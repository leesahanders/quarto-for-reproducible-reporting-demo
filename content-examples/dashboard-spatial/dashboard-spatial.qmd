---
title: "Contiguous United States Daily UV Forecast"
date: "last-modified"
date-format: "YYYY-MM-DD HH:mm"
format:
  dashboard:
    logo: images/Leafey.PNG
    nav-buttons:
    - icon: github
      href: "https://github.com/leesahanders/quarto-for-reproducible-reporting-demo"
editor: source
expandable: true
theme: lux
resource_files:
- custom.scss
- images/Leafey.PNG
---

<!-- Other good themes: morph, pulse, sandstone, spacelab, solar, slate, lux  -->

# DATE `r Sys.Date()`

<!-- Pull data for UV  -->

```{r}
#| echo: false
#| warning: false
#| message: false

library(httr)
library(httr2)
library(png)
library(xml2)
library(rvest)
library(tibble)
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyverse)
library(sf)
library(leaflet)
library(gt)
library(jsonlite)
library(data.table)

samplesize = 20

us_cities <- read.csv("data/us_cities.csv")

us_cities_manual <- us_cities %>%
  filter(CITY == "Boulder" & STATE_NAME == "Colorado")

# Randomly sample cities within each state, make sure 80304 is always included
us_cities_sample <- us_cities %>% 
  filter(!STATE_NAME %in% c("Hawaii", "Alaska")) %>%
  group_by(STATE_NAME) %>%
  slice_sample(n = samplesize) %>% 
  rbind(us_cities_manual)

# Try to load the cached data while developing to make things faster
flagcached = 1

if(flagcached == 1){
  if(file.exists(paste0(getwd(),"/tmp/data.RData"))){
    load(file="tmp/data.RData")
  }
}

if(!exists("uv_df")){

uv_df <- data.frame()
uv_hourly <- data.frame()

# Todo: Parallelize
for(i in 1:nrow(us_cities_sample)){
  print(paste0(i, "/", nrow(us_cities_sample), ": ", us_cities_sample[i,4], ", ", us_cities_sample[i,3]))
  
  # Get daily UV forecast (as xml)
  url <- paste0("https://data.epa.gov/efservice/getEnvirofactsUVDAILY/CITY/",us_cities_sample[i,4],"/STATE/",us_cities_sample[i,3])
  
  # Replace blanks with %20 
  url <- gsub(" ", "%20", url)
  
  # Get hourly UV forecast (as json)
  url_hourly <- paste0("https://data.epa.gov/efservice/getEnvirofactsUVHOURLY/CITY/",us_cities_sample[i,4],"/STATE/",us_cities_sample[i,3],"/JSON")    
  
  # Replace blanks with %20 
  url_hourly <- gsub(" ", "%20", url_hourly)

  #ERROR HANDLING
  possibleError <- tryCatch(
      uv <- request(url) |> req_perform(),
      error=function(e) e
  )
  
  #REAL WORK
  if(!inherits(possibleError, "error")){
    
    # Daily UV
    uv <- uv |>
      resp_body_xml()
  
    state <- xml_text(xml_find_all(uv, xpath = "//STATE"))
    uv_index <- xml_text(xml_find_all(uv, xpath = "//UV_INDEX"))
    uv_alert <- xml_text(xml_find_all(uv, xpath = "//UV_ALERT"))
    date <- xml_text(xml_find_all(uv, xpath = "//DATE"))
    id <- us_cities_sample[i,1]
    state_code <- us_cities_sample[i,2]
    state_orig <- us_cities_sample[i,3] 
    city <- us_cities_sample[i,4]
    county <- us_cities_sample[i,5]
    lat <- us_cities_sample[i,6]
    lng <- us_cities_sample[i,7]
    
    uv_df_tmp <- data.frame(state = state, uv_index = uv_index, uv_alert = uv_alert, date = date, id = id, state_code = state_code, state_orig = state_orig, city = city, county = county, lat = lat, lng = lng)
  
    uv_df <- rbind(uv_df, uv_df_tmp)    
    
    # Hourly UV
    uv_hourly_raw <- request(url_hourly) |> 
      req_perform() |>
      resp_body_json()     
    
    uv_hourly_tmp <- data.frame(rbindlist(uv_hourly_raw, fill=TRUE), uv_index = uv_index, uv_alert = uv_alert, date = date, id = id, state_code = state_code, state_orig = state_orig, county = county, lat = lat, lng = lng)
    
    uv_hourly <- rbind(uv_hourly, uv_hourly_tmp)   
    
  } 
}

uv_df_zip <- uv_hourly %>%
  # Add color
  mutate(uv_index = as.numeric(uv_index)) %>%
  mutate(color = case_when(
    uv_index <= 2 ~ "#6B990F",
    3 < uv_index &  uv_index <= 5 ~ "#FFFF32",
    5 < uv_index &  uv_index <= 7 ~ "#FF7F00",
    7 < uv_index &  uv_index <= 10 ~ "#E51932",
    uv_index >= 11 ~ "#6551CC",
    .default = "#E5E5E5"
  )) %>%
  mutate(color_name = case_when(
    uv_index <= 2 ~ "green",
    3 < uv_index &  uv_index <= 5 ~ "yellow",
    5 < uv_index &  uv_index <= 7 ~ "orange",
    7 < uv_index &  uv_index <= 10 ~ "red",
    uv_index >= 11 ~ "purple",
    .default = "white"
  )) %>%
  # Add pop-up text
  mutate(popup = paste0("Selected point","<hr>","UV index: ", uv_index, "<br>", "City: ", city, "<br>", "State: ", state))

uv_hourly_zip <- uv_df %>%
  # Add color
  mutate(uv_index = as.numeric(uv_index)) %>%
  mutate(color = case_when(
    uv_index <= 2 ~ "#6B990F",
    3 < uv_index &  uv_index <= 5 ~ "#FFFF32",
    5 < uv_index &  uv_index <= 7 ~ "#FF7F00",
    7 < uv_index &  uv_index <= 10 ~ "#E51932",
    uv_index >= 11 ~ "#6551CC",
    .default = "#E5E5E5"
  )) %>%
  mutate(color_name = case_when(
    uv_index <= 2 ~ "green",
    3 < uv_index &  uv_index <= 5 ~ "yellow",
    5 < uv_index &  uv_index <= 7 ~ "orange",
    7 < uv_index &  uv_index <= 10 ~ "red",
    uv_index >= 11 ~ "purple",
    .default = "white"
  )) %>%
  # Add pop-up text
  mutate(popup = paste0("Selected point","<hr>","UV index: ", uv_index, "<br>", "City: ", city, "<br>", "State: ", state))

  # For testing cache the data if it hasn't been already
  if(flagcached == 1){
    save.image(file="tmp/data.RData")
  }
}

# Resources: 
# Get all us cities: https://opendata.stackexchange.com/questions/18473/seeking-list-of-all-us-cities-and-their-latitude-and-longitude
# https://stackoverflow.com/questions/8093914/use-trycatch-skip-to-next-value-of-loop-upon-error/
# https://www.geeksforgeeks.org/convert-json-data-to-dataframe-in-r/
```


<!-- Use data based on zipcode -->

```{r}
#| echo: false
#| warning: false
#| message: false
#| content: valuebox
#| title: "UV Index"

# library(httr)
# library(httr2)
# library(png)
# library(xml2)
# library(rvest)
# library(tibble)
# library(knitr)
# library(kableExtra)
# library(dplyr)
# library(tidyverse)
# library(sf)
# library(leaflet)
# library(gt)
# library(zipcodeR)
# library(sp)
# #library(ggmap)
# 
# zipcodes_eastern <- search_tz('Eastern')
# zipcodes_mountain <- search_tz('Mountain')
# zipcodes_central <- search_tz('Central')
# zipcodes_pacific <- search_tz('Pacific')
# 
# samplesize = 100
# 
# # Randomly sample zipcodes by timezone to make sure there is coverage, make sure 80304 is always included
# zipcodes <- c(sample(x = zipcodes_eastern$zipcode, size = samplesize), 
#               sample(x = zipcodes_mountain$zipcode, size = samplesize), 
#               sample(x = zipcodes_central$zipcode, size = samplesize), 
#               sample(x = zipcodes_pacific$zipcode, size = samplesize),"80304") %>%
#   unique()
# 
# # Downselect for testing
# #zipcodes <- c("80304","80302","80301","80310","80303","80305","80025","77024","77025","77030","77035","77096","77320","77342","77334")
# 
# output_format <- c("XML", "JSON", "EXCEL", "CSV")[1] ## As XML 
# # Test from terminal with: curl "https://data.epa.gov/efservice/getEnvirofactsUVDAILY/ZIP/80304/XML"
# 
# # Try to load the cached data while developing to make things faster
# flagcached = 1
# 
# if(flagcached == 1){
#   if(file.exists(paste0(getwd(),"/tmp/data.RData"))){
#     load(file="tmp/data.RData") 
#   }
# }

# if(!exists("uv_df")){
#   
# uv_df <- data.frame()
# uv_today <- data.frame()
# 
# zcta_place_rel_10 <- read.table("data/zcta_place_rel_10.txt",sep = ",", header = TRUE)
# USA_ZIP_Code_Boundaries <- read.csv("data/USA_ZIP_Code_Boundaries.csv")
# 
# # Todo: Parallelize
# for(i in zipcodes){
#   print(i)
#   # Get UV forecast
#   url <- paste0("https://data.epa.gov/efservice/getEnvirofactsUVDAILY/ZIP/",i,"/",output_format)
# 
#   uv <- request(url) |>
#     req_perform() |>
#     resp_body_xml()
# 
#   state <- xml_text(xml_find_all(uv, xpath = "//STATE"))
#   uv_index <- xml_text(xml_find_all(uv, xpath = "//UV_INDEX"))
#   uv_alert <- xml_text(xml_find_all(uv, xpath = "//UV_ALERT"))
#   date <- xml_text(xml_find_all(uv, xpath = "//DATE"))
# 
#   uv_df_tmp <- data.frame(state = state,  zipcode = i, uv_index = uv_index, uv_alert = uv_alert, date = date)
# 
#   uv_df <- rbind(uv_df, uv_df_tmp)
# 
#   # Get census data for zipcode geocoding 
#   # url <- paste0("https://geocoding.geo.census.gov/geocoder/geographies/address?street=4600+Silver+Hill+Rd&city=Washington&state=DC&benchmark=Public_AR_Census2020&vintage=Census2020_Census2020&layers=10&format=json")
#   # url <- paste0("https://geocoding.geo.census.gov/geocoder/geographies/address?street=4600+Silver+Hill+Rd&city=Washington&state=DC&benchmark=Public_AR_Census2020&vintage=Census2020_Census2020&format=json")
#   # url <- paste0("https://geocoding.geo.census.gov/geocoder/geographies/address?street=4600+Silver+Hill+Rd&city=Washington&state=DC&zipcode=20233&benchmark=Public_AR_Census2020&vintage=Census2020_Census2020&format=json")
#   url <- paste0("https://geocoding.geo.census.gov/geocoder/geographies/address?zipcode=20233&benchmark=Public_AR_Census2020&vintage=Census2020_Census2020&format=json")
# 
#   geocode <- request(url) |>
#   req_perform() |>
#   resp_body_json()
#   
#   geocode$result$addressMatches[[1]]$coordinates$y
#   geocode$result$addressMatches[[1]]$coordinates$x
#   
# }
# 
# uv_df_zip <- uv_df %>%
#   # Add geocode
#   mutate(lat = geocode_zip(zipcode)$lat) %>% # Using zipcoder, wrong?
#   mutate(lng = geocode_zip(zipcode)$lng) %>% # Using zipcoder, wrong?
#   # Add color
#   mutate(uv_index = as.numeric(uv_index)) %>%
#   mutate(color = case_when(
#     uv_index <= 2 ~ "#6B990F",
#     3 < uv_index &  uv_index <= 5 ~ "#FFFF32",
#     5 < uv_index &  uv_index <= 7 ~ "#FF7F00",
#     7 < uv_index &  uv_index <= 10 ~ "#E51932",
#     uv_index >= 11 ~ "#6551CC",
#     .default = "#E5E5E5"
#   )) %>%
#   mutate(color_name = case_when(
#     uv_index <= 2 ~ "green",
#     3 < uv_index &  uv_index <= 5 ~ "yellow",
#     5 < uv_index &  uv_index <= 7 ~ "orange",
#     7 < uv_index &  uv_index <= 10 ~ "red",
#     uv_index >= 11 ~ "purple",
#     .default = "white"
#   )) %>%
#   # Add pop-up text
#   mutate(popup = paste0("Selected point","<hr>","UV index: ", uv_index, "<br>", "Zipcode: ", zipcode, "<br>", "State: ", state))
# 
#   # For testing cache the data if it hasn't been already
#   if(flagcached == 1){
#     save.image(file="tmp/data.RData")
#   }
# }

# Resources: 
# https://www.reddit.com/r/scacjdiscussion/comments/12qpj80/how_do_you_find_an_accurate_uv_index_forecast/
# https://pyowm.readthedocs.io/en/latest/v3/uv-api-usage-examples.html (deprecated 2021) 
# https://openweathermap.org/api/uvi (deprecated 2021)
# https://openweathermap.org/api/one-call-3 (requires pricing)
# https://www.epa.gov/enviro/web-services#uvindex
# https://github.com/r-lib/httr2/issues/344
# https://stackoverflow.com/questions/73555055/converting-a-xml-page-to-a-data-frame/73556402#73556402
# https://stackoverflow.com/questions/69940271/embed-xml-from-file-into-rmd
# https://www.robwiederstein.org/2021/03/05/xml-to-dataframe/
# https://www.epa.gov/enviro/envirofacts-data-service-api
# Search zipcodes: https://www.unitedstateszipcodes.org/
# Uv index reference: https://19january2017snapshot.epa.gov/sunsafety/uv-index-scale-1_.html
# Color pallettes: https://r-charts.com/color-palettes/ 
# More recent zipcode block relationship files from 2020 census: https://www.census.gov/geographies/reference-files/time-series/geo/relationship-files.2020.html 
# Census geocoding service: https://www.census.gov/data/developers/data-sets/Geocoding-services.html 
# https://opendata.stackexchange.com/questions/13715/search-population-zipcode-by-city-from-us-census-api
# Zipcode map of Dallas: https://stackoverflow.com/questions/59539423/creating-a-zipcode-map-in-r 
# ARCgis api: https://developers.arcgis.com/rest/geocode/api-reference/overview-world-geocoding-service.htm 
# USA zipcode boundaries: https://hub.arcgis.com/datasets/esri::usa-zip-code-boundaries/about 
# Open and plot shapefiles: https://r-graph-gallery.com/168-load-a-shape-file-into-r.html 
```

## Row {.tabset height=100%}

### UV Map with leaflet

<!-- UV Map with leaflet -->

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: plot-map
#| tbl-cap: "UV Map"
#| padding: 0px

# Find the grid forecast endpoint with this url: https://api.weather.gov/points/{latitude},{longitude}
# https://api.weather.gov/points/40.04,-105.23

# leaflet() %>%
#   addTiles() %>%
#   setView(lng = -105.23, lat = 40.04, zoom = 7) %>%
#   # Add UV data
#   addCircleMarkers(#data = uv_df_zip, color = uv_df_zip$color,
#                    #data = getMapData(map),
#                    lng = uv_df_zip$lat,
#                    lat = uv_df_zip$lng,
#                    color = uv_df_zip$color,
#                    popup = paste0("Selected point","<hr>","UV index: ",uv_df_zip$uv_index, "<br>", "Zipcode: ", uv_df_zip$zipcode, "<br>", "State: ", uv_df_zip$state)) %>%
#   #addCircles(data = uv_df_zip, radius = 2000) %>%
#   # Add legend
#   # addLegend(data = uv_df_zip,
#   #           position = "bottomright",
#   #           colors = arrange(unique(uv_df_zip %>% select(color, uv_index))$color),
#   #           labels = arrange(unique(uv_df_zip %>% select(color, uv_index))$uv_index),
#   #           title = "Legend",
#   #           opacity = 1) %>%
#   # Add measurement tool - for fun
#   addMeasure(
#     position = "bottomleft",
#     primaryLengthUnit = "meters",
#     primaryAreaUnit = "sqmeters",
#     activeColor = "#3D535D",
#     completedColor = "#7D4479") %>%
#   # Add daylight layer
#   addTerminator() %>%
#   # Add minimap
#   addMiniMap(width = 150, height = 150)

leaflet(data = uv_df_zip) %>%
  addTiles() %>%
  # addTiles(providers$Stadia.StamenToner, group = "Toner") %>%
  setView(lng = -105.23, lat = 40.04, zoom = 7) %>%
  # Add UV data
  addCircleMarkers(lng = ~LONGITUDE,
                   lat = ~LATITUDE,
                   color = ~color,
                   stroke = FALSE, fillOpacity = 0.5, 
                   radius = ~ifelse(uv_alert == "0", 6, 10),
                   popup = ~popup) %>%
  #addMarkers(lng=~LONGITUDE, lat=~LATITUDE, popup=~popup) %>%
  # # Add legend
  # addLegend(data = uv_df_zip,
  #           position = "bottomright",
  #           colors = arrange(unique(uv_df_zip %>% select(color, uv_index))$color),
  #           labels = arrange(unique(uv_df_zip %>% select(color, uv_index))$uv_index),
  #           title = "Legend",
  #           opacity = 1) %>%
  # # Add measurement tool - for fun
  # addMeasure(
  #   position = "bottomleft",
  #   primaryLengthUnit = "meters",
  #   primaryAreaUnit = "sqmeters",
  #   activeColor = "#3D535D",
  #   completedColor = "#7D4479") %>%
  # Add daylight layer
  addTerminator() %>%
  # Add minimap
  addMiniMap(width = 150, height = 150)

# References 
# https://r-charts.com/spatial/interactive-maps-leaflet/
# https://warin.ca/posts/rcourse-datavisualizationwithr-interactivemaps/
# https://www.library.virginia.edu/data/articles/data-scientist-as-cartographer-an-introduction-to-making-interactive-maps-in-r-with-leaflet
```


### UV Choropleth Map

<!-- UV Choropleth Map -->

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: plot-map-choropleth
#| tbl-cap: "UV Map"
#| padding: 0px


# TODO: 
# https://lucaliehner.com/blog/mapping-zip-codes-to-shapefiles-in-r-with-ggplot-g/ 
# https://rstudio.github.io/leaflet/articles/choropleths.html
```


### Data

<!-- UV Map Raw Data -->

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: tbl-map
#| tbl-cap: "UV Map Raw Data"

uv_df_zip %>%
  kbl(booktabs = T, align = "lc") %>% #, caption = "RSS Feed for R-weekly") %>%
  kable_styling() %>%
  kable_paper(full_width = T)
```


## Row {height=15%}

<center>

[![](images/uv_index_scale_epa.png){width=20% fig-align="c"}](https://19january2017snapshot.epa.gov/sunsafety/uv-index-scale-1_.html)

</center>

